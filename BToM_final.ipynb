{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Theory Of Mind Problem Set\n",
    "\n",
    "\n",
    "1. [Building The Model](#Distance-Calc)\n",
    "  1. [Initializing The Model](#init)\n",
    "  1. [Distance-Calc](#Distance-Calc)\n",
    "  2. [Getting Points Within The Range](#Within-Range)\n",
    "2. [The Mind Model](#Mind-Model)\n",
    "  1. [Updating Beliefs](#updating-beliefs)\n",
    "  2. [Transition Matrix](#transition-matrix)\n",
    "  3. [Inferring Intent](#inferring-intent)\n",
    "3. [Analysis of Bayesian Theory Of Mind](#analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building The Model\n",
    "\n",
    "<img src=\"scenario.png\"/>\n",
    "\n",
    "\n",
    "Before we start constructing a way to infer intent, we first need to find a way to represent our \"world\", the space in which we will infer intent. In this case, our world is a 15x15 square grid that our agent (in this case, Mark Watney) can traverse around. Scattered in known locations on the grid are resources A B and C. Mark is trying to retrieve these resources, but we're not sure which one he wants. This is where the intent comes in!\n",
    "\n",
    "To be more technical and specific, we will write some class Mind that keeps track of our model's estimation of Mark's intent, belief about the world, and how likely he's going for a certain resource given his location.\n",
    "\n",
    "Below, we'll initialize this Mind class, then dive a bit deeper into how to use it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize The Mind (5 pts) <a id=\"temporal-word-problem\"/>\n",
    "\n",
    "Our first step is to initialize the Bayesian Theory of Mind. Below is a skeleton implementation of the class we'll use to model our BToM. We've initialized some stuff for you, but you'll have to do the rest. Let's initialize both our beliefs and our intents as a *uniform distribution*. That is, the probability for any belief or any intent starts out the same. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mind:\n",
    "    def __init__(self):\n",
    "        # where resources are\n",
    "        self.world_loc = [(10,0), (0,9), (6,10)] # this array is the coordinates of the location of the resources\n",
    "        self.map_length = 15 # How large the grid is\n",
    "        self.world_state = 'ABC' # Resources\n",
    "    \n",
    "        self.beliefs_worlds = ['ABC', 'ACB', 'BAC', 'BCA', 'CAB', 'CBA'] # Possible Beliefs\n",
    "\n",
    "        self.state = (0,0)\n",
    "\n",
    "        self.beliefs = [1/6, 1/6, 1/6, 1/6, 1/6, 1/6]\n",
    "        self.intents = {'A': 1/3,'B': 1/3,'C': 1/3}\n",
    "        \n",
    "        self.states = []\n",
    "        for i in range(self.map_length):\n",
    "            for j in range(self.map_length):\n",
    "                self.states.append((i,j))\n",
    "\n",
    "        self.gamma = 0.5\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-557370c6a2aeba55",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "source": [
    "from nose.tools import assert_equal\n",
    "\n",
    "my_mind = Mind()\n",
    "\n",
    "assert_equal(my_mind.beliefs, [1/6, 1/6, 1/6, 1/6, 1/6, 1/6])\n",
    "assert_equal(my_mind.intents, {'A': 1/3,'B': 1/3,'C': 1/3})\n",
    "\n",
    "print (\"success\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance Calculation (5 pts) <a id=\"distance-calc\"/>\n",
    "\n",
    "In order for our model to understand anything, we need to be able to calculate distances between objects on our field. Write a function here to calculate the distance between two points p1 and p2 (both tuples of the form x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper to get distance\n",
    "def get_distance(p1, p2):\n",
    "    #pass\n",
    "    return ((p1[0]-p2[0])**2 + (p1[1]-p2[1])**2)**.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test that our Distance Calculation Works as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-5be901e3420da294",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "source": [
    "from nose.tools import assert_equal\n",
    "\n",
    "assert_equal(get_distance((1,0), (2,0)), 1)\n",
    "assert_equal(get_distance((1,1), (2,2)), (2)**0.5)\n",
    "assert_equal(get_distance((1,0), (1,2)), 2)\n",
    "\n",
    "print (\"success\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Points Within A Range (10 pts) <a id=\"within-range\"/>\n",
    "\n",
    "Now, our next step is to be able to find the points that Mark can see when he is at some location. Implement the method below, that given a Mind object and location, returns all the resources that Mark can see. (5 squares away in x or y direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def within_range(mind, position):\n",
    "    \"\"\" \n",
    "    Given a mind object and location, outputs the (x,y) coordinates of resources near the location\n",
    "    \n",
    "    Input: mind - a mind object which contains location of all the resources on map\n",
    "           position - current position on map\n",
    "    Output: locs - a list of locations (in x,y) available from current position\n",
    "    \"\"\"\n",
    "    # should return resource positions that are visible from current position\n",
    "#     locs = []\n",
    "    \n",
    "#     return locs\n",
    "\n",
    "    locs = []\n",
    "    for i in range(len(mind.world_loc)):\n",
    "        loc = mind.world_loc[i]\n",
    "        if abs(position[0]-loc[0])<=5 and abs(position[1]-loc[1])<=5:\n",
    "            locs.append(loc)\n",
    "    return locs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-069f8f72f4ccd00b",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "source": [
    "from nose.tools import assert_equal\n",
    "\n",
    "my_mind = Mind()\n",
    "\n",
    "assert_equal(within_range(my_mind, (8,0)), [(10, 0)])\n",
    "assert_equal(within_range(my_mind, (0,0)), [])\n",
    "assert_equal((6,10) in within_range(my_mind, (3,9)) and (0,9) in within_range(my_mind, (3,9)), True)\n",
    "print (\"success\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Mind Model\n",
    "\n",
    "Next, we need to actually write some useful functions that will use the mind model to get intent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating Beliefs (20 pts) <a id=\"updating-beliefs\"/>\n",
    "\n",
    "In this section, we'll work on updating what our BToM thinks that Mark believes.\n",
    "\n",
    "The function below is passed a mind instance and the current state. We should update our probability distribution of what we think Mark believes given this new information.\n",
    "\n",
    "Here are the steps you should follow:\n",
    "- Obtain all locations of resources that are within range of our state (use a function you made!)\n",
    "For each of the locations you will then:\n",
    "- Get the resource that is at that location in the actual world\n",
    "- Go through all the 6 possible worlds, keep track of which are consistent and inconsistent with the resource being in that location.\n",
    "- For each of the consistent worlds, multiply the previous belief in that world by 0.9 over the number of consistent worlds.\n",
    "- Similarly for the inconsistent worlds, multiply the previous belief in that world by 0.1 over the number of inconsistent worlds.\n",
    "- Normalize the new beliefs\n",
    "\n",
    "Hint: If the position of the resource we just discovered matches some possible state of the world, Mark is also much more likely to think that that is the true state of the world.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beliefs_update(mind, state):\n",
    "    \"Update beliefs\"\n",
    "    near_locations = within_range(mind, state)\n",
    "\n",
    "    # figure out which locations you can see\n",
    "    # update beliefs for the ones close to you\n",
    "\n",
    "    #redistribute beliefs\n",
    "\n",
    "    for loc in near_locations:\n",
    "        i = mind.world_loc.index(loc)\n",
    "        resource = mind.world_state[i]\n",
    "        print (\"observed resource %s\" % resource)\n",
    "        consistently_observed_worlds = []\n",
    "        inconsistently_observed_worlds = []\n",
    "        for j in range(len(mind.beliefs_worlds)):\n",
    "            world = mind.beliefs_worlds[j]\n",
    "            if world[i] == resource:\n",
    "                consistently_observed_worlds.append(j)\n",
    "            else:\n",
    "                inconsistently_observed_worlds.append(j)\n",
    "        factor = len(consistently_observed_worlds)\n",
    "        sum_of_consistently_observed = sum([mind.beliefs[i] for i in consistently_observed_worlds])\n",
    "        sum_of_inconsistently_observed = sum([mind.beliefs[i] for i in inconsistently_observed_worlds])\n",
    "        for i in range(len(mind.beliefs)):\n",
    "            if i in consistently_observed_worlds:\n",
    "                mind.beliefs[i] = 0.9 * mind.beliefs[i]/sum_of_consistently_observed\n",
    "            else:\n",
    "                mind.beliefs[i] = 0.1 * mind.beliefs[i]/sum_of_inconsistently_observed\n",
    "\n",
    "        mind.beliefs = [float(i)/sum(mind.beliefs) for i in mind.beliefs]\n",
    "        print(\"new beliefs %s \" % mind.beliefs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e638d4dae4812c55",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observed resource A\n",
      "new beliefs [0.45, 0.45, 0.025, 0.025, 0.025, 0.025] \n",
      "observed resource B\n",
      "new beliefs [0.8526315789473684, 0.08571428571428572, 0.004761904761904762, 0.004761904761904762, 0.004761904761904762, 0.04736842105263158] \n",
      "success\n"
     ]
    }
   ],
   "source": [
    "from nose.tools import assert_equal, assert_true\n",
    "\n",
    "my_mind = Mind()\n",
    "\n",
    "beliefs_update(my_mind, (10,0))\n",
    "assert_equal(my_mind.beliefs[0], 0.45)\n",
    "beliefs_update(my_mind, (0,9))\n",
    "assert_true(abs(my_mind.beliefs[0]-0.85)<0.01)\n",
    "\n",
    "print (\"success\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Transition and Actions (20 pts) <a id=\"transition-matrix\"/>\n",
    "\n",
    "In addition to wanting to figure out Mark's intent, our model also models Mark's mind in the context of a planning problem as well. We'd like to know what action Mark wants to take next. Although this also includes the value iteration algorithm as well as getting the best policy (the best actions he should take), we'll be defining just some of the functions necessary to get the best policy.\n",
    "\n",
    "We'll be implementing a function, transition, that giving a state and an action, returns a list of (result state, probability) pairs. \n",
    "\n",
    "Hint: We included two helper function, get_next_state, that gives the next state that would be reached by taking some action, and actions, which gets the next set of possible functions. Use them to help implement transition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_state(mind, state, action):\n",
    "    \"\"\"\n",
    "    Helper function. Given state and action, gives next state that would\n",
    "    be reached. Returns None if off map.\n",
    "    \"\"\"\n",
    "    next_state = None\n",
    "    x = state[0]\n",
    "    y = state[1]\n",
    "\n",
    "    if action == 'right':\n",
    "        if 0<=(x+1)<mind.map_length and 0<=y<mind.map_length:\n",
    "            next_state = (x+1,y)\n",
    "    elif action == 'left':\n",
    "        if 0<=(x-1)<mind.map_length and 0<=y<mind.map_length:\n",
    "            next_state = (x-1,y)\n",
    "    elif action == 'up':\n",
    "        if 0<=x<mind.map_length and 0<=(y-1)<mind.map_length:\n",
    "            next_state = (x,y-1)\n",
    "    elif action == 'down':\n",
    "        if 0<=x<mind.map_length and 0<=(y+1)<mind.map_length:\n",
    "            next_state = (x,y+1)\n",
    "\n",
    "    return next_state\n",
    "\n",
    "\n",
    "def actions(mind, state):\n",
    "    \"Set of actions that can be performed in this state.\"\n",
    "    actions = []\n",
    "    x = state[0]\n",
    "    y = state[1]\n",
    "\n",
    "    if 0<=(x+1)<mind.map_length and 0<=y<mind.map_length:\n",
    "        actions.append('right')\n",
    "    if 0<=(x-1)<mind.map_length and 0<=y<mind.map_length:\n",
    "        actions.append('left')\n",
    "    if 0<=x<mind.map_length and 0<=(y-1)<mind.map_length:\n",
    "        actions.append('up')\n",
    "    if 0<=x<mind.map_length and 0<=(y+1)<mind.map_length:\n",
    "        actions.append('down')\n",
    "\n",
    "    return actions\n",
    "\n",
    "    \n",
    "def transition(mind, state, action):\n",
    "    \"\"\"\n",
    "    Transition model.  From a state and an action, return a list\n",
    "    of (result-state, probability) pairs.\n",
    "    \"\"\"\n",
    "    pos_actions = actions(mind, state)\n",
    "    pairs = []\n",
    "\n",
    "    action_valid = False\n",
    "    next_state = get_next_state(mind, state, action)\n",
    "\n",
    "    x = state[0]\n",
    "    y = state[1]\n",
    "\n",
    "    if next_state:\n",
    "        pairs.append((next_state, 0.9))\n",
    "        remaining = len(pos_actions) - 1\n",
    "        prob = 0.1 / remaining\n",
    "        for a in pos_actions:\n",
    "            if a != action:\n",
    "                pairs.append((get_next_state(mind, state, a), prob))\n",
    "    else:\n",
    "        prob = 1.0 / len(pos_actions)\n",
    "        for a in pos_actions:\n",
    "            pairs.append((get_next_state(mind, state, a), prob))\n",
    "\n",
    "    return pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-9e5f8fbeb17ee09c",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((1, 2), 0.9), ((2, 1), 0.03333333333333333), ((0, 1), 0.03333333333333333), ((1, 0), 0.03333333333333333)]\n",
      "[((5, 3), 0.9), ((3, 3), 0.03333333333333333), ((4, 2), 0.03333333333333333), ((4, 4), 0.03333333333333333)]\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "from nose.tools import assert_equal\n",
    "\n",
    "my_mind = Mind()\n",
    "print(transition(my_mind, (1,1), 'down'))\n",
    "assert_equal(transition(my_mind, (1,1), 'down'), [((1, 2), 0.9), ((2, 1), 0.03333333333333333), ((0, 1), 0.03333333333333333), ((1, 0), 0.03333333333333333)]\n",
    ")\n",
    "\n",
    "print(transition(my_mind, (4,3), 'right'))\n",
    "assert_equal(transition(my_mind, (4,3), 'right'), [((5, 3), 0.9), ((3, 3), 0.03333333333333333), ((4, 2), 0.03333333333333333), ((4, 4), 0.03333333333333333)]\n",
    ")\n",
    "\n",
    "\n",
    "print (\"success\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferring Intent (20 pts) <a id=\"inferring-intent\"/>\n",
    "\n",
    "Last thing! We need to put it together and infer the intent of Mark using the functions we've defined!\n",
    "\n",
    "In this function, we're passed in a Mind object. Using it, we should get the total probability (normalized) that Mark's intent is to get a particular resource.\n",
    "\n",
    "Steps:\n",
    "- Based on the action Mark takes next, get the next state\n",
    "- For each of the resource positions in the actual world orientation, get the difference in distance Mark is from each of the resource positions based on the state before and after his action. Note: some of these may be negative.\n",
    "- For each of the resources, taking into account the belief distribution in all the different worlds, we want to calculate a score, based on the distance it is from Mark in that world and the belief in that world (to simplify, you can simply multiply the distance by the belief).\n",
    "- Update the old intents by adding this score, discounted by a factor of 0.3. Ensure that the values do not exceed 1 or go below 0.\n",
    "- Finally, normalize the new intents.\n",
    "\n",
    "More specifically, you should mutate mind.intents and update it with the new intents! We've already implemented the step for receiving an observation, and updating other propertiess, but now you must finish it with update_intents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def intents_update(self, action):\n",
    "#     \"Update intents.\"\n",
    "#     \"\"\"\n",
    "#         belief: [Pr(ABC), Pr(ACB), Pr(BAC), Pr(BCA), Pr(CAB), Pr(CBA)]\n",
    "#         state: current location on the grid\n",
    "#         action: action he takes\n",
    "#     \"\"\"\n",
    "\n",
    "#     next_state = self.get_next_state(self.state, action)\n",
    "\n",
    "#     # difference in distance that this action takes us, or how much closer or farther\n",
    "#     # we get from the 3 resource locations\n",
    "#     dists = []\n",
    "\n",
    "#     for resource_pos in self.world_loc:\n",
    "#         dist1 = self.get_distance(resource_pos, self.state)\n",
    "#         dist2 = self.get_distance(resource_pos, next_state)\n",
    "#         diff_dist = dist1-dist2\n",
    "#         dists.append(diff_dist)\n",
    "\n",
    "#     print (dists)\n",
    "\n",
    "#     new_intents_scores = {'A': 0, 'B': 0, 'C': 0}\n",
    "\n",
    "#     for i in range(len(self.beliefs_worlds)):\n",
    "#         world = self.beliefs_worlds[i]\n",
    "#         belief = self.beliefs[i]\n",
    "#         for i in range(3):\n",
    "#             r = world[i]\n",
    "#             new_intents_scores[r] += dists[i] * belief\n",
    "\n",
    "#     new_intents = {}\n",
    "#     factor = 0.3\n",
    "#     sum_new_intents = 0\n",
    "#     for r in self.intents:\n",
    "#         new_intents[r] = max(self.intents[r] + factor * new_intents_scores[r], 0)\n",
    "#         sum_new_intents += new_intents[r]\n",
    "\n",
    "#     self.intents = {'A': new_intents['A']/sum_new_intents, 'B': new_intents['B']/sum_new_intents, 'C': new_intents['C']/sum_new_intents}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def receive_observation(mind, action):\n",
    "    \"Receive observation, update model, and get updated intents.\"\n",
    "    print (\"------\")\n",
    "    mind.state = get_next_state(mind, state, action)\n",
    "    beliefs_update(mind, mind.state)\n",
    "#     U = value_iteration(mind)\n",
    "#     policy = best_policy(mind, U)\n",
    "#     intents_update(mind, action)\n",
    "#     print ('intents: ', self.intents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-1358f808a1e3f350",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_equal\n",
    "\n",
    "my_mind = Mind()\n",
    "\n",
    "# TODO update this too!!!\n",
    "\n",
    "# receive_observation(my_mind,1, 0)\n",
    "# receive_observation(my_mind,2, 0)\n",
    "# receive_observation(my_mind,3, 0)\n",
    "# receive_observation(my_mind,4, 0)\n",
    "# receive_observation(my_mind,5, 0)\n",
    "# receive_observation(my_mind,6, 0)\n",
    "# receive_observation(my_mind,5, 0)\n",
    "# receive_observation(my_mind,4, 0)\n",
    "# receive_observation(my_mind,3, 0)\n",
    "\n",
    "# #{'A': 0.035648663780556554, 'B': 0.48217566810972184, 'C': 0.48217566810972157}\n",
    "\n",
    "# assert_equal(abs(my_mind.intents['A'] - 0.035648663780556554) < 0.001, True)\n",
    "\n",
    "# assert_equal(abs(my_mind.intents['B'] - 0.48217566810972184) < 0.001, True)\n",
    "\n",
    "# assert_equal(abs(my_mind.intents['C'] - 0.48217566810972157) < 0.001, True)\n",
    "\n",
    "# print (\"successs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Bayesian Theory of Mind (10 pts) <a id=\"distance-calc\"/>\n",
    "\n",
    "In the box below, highlight some of the advantages and disadvantages of Bayesian Theory of Mind. This is open ended! What makes it different from other approaches, and why does that make it better? Are there any drawbacks you can think of?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e982caeeb74c73ac",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
